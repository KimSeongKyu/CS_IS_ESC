# 1. 로드밸런서란?

* 인스턴스 하나로 처리하기 힘든 부하를 **여러 대의 인스턴스로 분산하여 처리량을 늘릴 수 있다.**
* 장애가 발생했거나 점검 중인 인스턴스를 자동으로 서비스에서 제외시켜 가용성을 높일 수 있다.
* 서버에 가해지는 부하(=로드)를 분산(=밸런싱)해주는 장치 또는 기술을 통칭한다.
* 클라이언트와 서버풀(Server Pool, 분산 네트워크를 구성하는 서버들의 그룹) 사이에 위치   
* **한 대의 서버로 부하가 집중되지 않도록 트래픽을 관리해 각각의 서버가 최적의 퍼포먼스를 보일 수 있도록 한다.**

<p align="center"><img src="https://user-images.githubusercontent.com/50662573/107877340-2ae86d00-6f0f-11eb-8a25-e5bef2047ab4.png" width="70%" height="70%"></img></p>

## 로드밸런서가 왜 필요한가?
* 현대의 모든 정보는 인터넷을 통해 연결되어있다. 인터넷의 발달은 데이터 통신을 보다 활발하게 만들었고 이는 트래픽의 폭발적인 증가로 이어졌다.   
그 결과 아무리 성능이 뛰어난 서버라고 해도 모든 트래픽을 감당해낼 수 없다. 이에 기업들은 서버를 추가하고 여러 대의 서버에 동일한 데이터를 저장해 수많은 트래픽을 효과적으로 분산하게 된다. 하지만 단순히 서버를 구축해 운영해도 모든 클라이언트의 요청에 일관성 있게 응답할 수 없다.   
* **쏟아지는 트래픽을 여러 대의 서버로 분산해주는 기술이 없다면 한 곳의 서버에 모든 트래픽이 몰릴 것이다.    
이때 필요한 기술이 바로 로드밸런싱이다.**

## 로드밸런싱은 모든 경우에 항상 필요한가?
    로드밸런싱은 여러 대의 서버를 두고 서비스를 제공하는 분산 처리 시스템에서 필요한 기술이다.    
    서비스의 제공 초기 단계라면 적은 수의 클라이언트로 인해 서버 한 대로 요청에 응답하는 것이 가능하다.   
    하지만 사업의 규모가 확장되고, 클라이언트의 수가 늘어나게 되면 기존 서버만으로는 정상적인 서비스가 불가능하게된다.   
    이처럼 증가한 트래픽에 대처할 수 있는 방법은 크게 두 가지다.   
    
<p align="center"><img src="https://post-phinf.pstatic.net/MjAxOTEyMTBfMjk1/MDAxNTc1OTU1MDI2NTY4.Zxj8nWGb6G6jtHDAZPPDf-dPZnpb_hsd7ydWw5lW7vAg.AucOXPJnmLyGiHr8KpVD9Dsy59FsWv5p7qJnSyW_YFAg.JPEG/%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1_%EC%8A%A4%EC%BC%80%EC%9D%BC.jpg" width="70%" height="70%"></img></p>

1. **Scale-up** : **서버 자체의 성능을 확장**하는 것이다. 비유하자면 CPU가 i3인 컴퓨터를 i7으로 **업그레이드**하는 것과 같다.    

2. **Scale-out** : 기존 서버와 동일하거나 낮은 성능의 **서버를 두 대 이상 증설하여 운영**하는 것이다. 비유하자면 CPU가 i3인 컴퓨터를 **여러 대 추가** 구입해 운영하는 것이다.   

   >**Scale-out** 의 방식으로 서버를 증설하기로 결정하였다면 **여러 대의 서버로 트래픽을 균등하게 분산해주는 로드밸런싱**이 반드시 필요하다.
    
## 로드밸런싱 알고리즘

>클라이언트의 요청을 특정 서버에 분배하는 로드밸런싱 기법은 여러 가지 있다. 활용할 수 있는 부하 분산 방식(로드밸런싱 알고리즘)에 어떠한 것들이 있는지 알아보겠다.  

* **라운드로빈 방식(Round Robin Method) : 순차 선택**

  * 트래픽을 전달할 인스턴스를 **순차적으로 선택하는 가장 기본적이고 대중적인 로드 밸런싱 방식**이다.
  * 모든 멤버 인스턴스들이 **같은 요청에 대해서 동일한 응답을 하는 경우**에 사용할 수 있는 방식이다.
  * 클라이언트의 요청을 순서대로 분배하기 때문에 **여러 대의 서버가 동일한 스펙**을 갖고 있고, **서버와의 연결(세션)이 오래 지속되지 않는 경우**에 활용하기 적합하다.

* **가중 라운드로빈 방식(Weighted Round Robin Method)**
 
  * 각각의 서버마다 가중치를 매기고 **가중치가 높은 서버에 클라이언트 요청을 우선적으로 배분**한다.
  * 주로 **서버의 트래픽 처리 능력이 상이한 경우 사용**되는 부하 분산 방식이다.
  * A 서버가 5라는 가중치를 갖고 B 서버가 2라는 가중치를 갖는다면, 로드밸런서는 라운드로빈 방식으로 A 서버에 5개, B 서버에 2개의 요청을 전달한다.
  
* **IP 해시 방식(IP Hash Method) or 원본 IP 기준 선택(Source IP)**

  * **클라이언트의 원본 IP 주소**를 **특정 서버로 매핑하여 요청을 처리**하는 방식이다.
  * **사용자의 IP를 해싱**해(Hashing, 임의의 길이를 지닌 데이터를 고정된 길이의 데이터로 매핑하는 것, 또는 그러한 함수) 로드를 분배하기 때문에 **사용자가 항상 동일한 서버로 연결되는 것을 보장**한다.
  * 한 사용자의 요청을 매번 동일한 인스턴스에서 처리하고자 할 때 유용
  
* **최소 연결 방식(Least Connection Method)**

  * 요청이 들어온 시점에 **가장 적은 연결상태**를 보이는 서버에 우선적으로 트래픽을 배분한다.   
  ( 현재 TCP 연결 수가 가장 작은 인스턴스를 선택하는 방식 - TCP 연결 수를 기준으로 하여 인스턴스들의 부하 상태를 파악하고 멤버 중
  가장 부하가 적은 인스턴스로 보내 가능한 균등하게 요청이 처리될 수 있도록 한다. 요청에 따른 처리 부하가 변동이 심할 때 적용한다면, 
  특정 인스턴스에 부하가 집중되는 상황을 방지할 수 있다. )
  * 자주 세션이 길어지거나, 서버에 분배된 트래픽들이 일정하지 않은 경우에 적합한 방식이다.
  
* **최소 리스폰타임(Least Response Time Method)**

  * 서버의 현재 연결 상태와 응답시간(Response Time, 서버에 요청을 보내고 최초 응답을 받을 때 까지 소요되는 시간)을 모두 고려하여 트래픽을 배분한다.
  * **가장 적은 연결 상태**와 **가장 짧은 응답시간**을 보이는 서버에 우선적으로 로드를 배분하는 방식이다.
  
## 로드밸런서 지원 프로토콜

* TCP
* HTTP
* HTTPS
* TERMINATED_HTTPS

  >  위의 프로토콜 중 TERMINATED_HTTPS 프로토콜은 HTTPS 트래픽을 수신하여 멤버 인스턴스에게는 HTTP 트래픽으로 전달하는 방식이다.
    TERMINATED_HTTPS 프로토콜을 사용하는 경우 최종 사용자와 로드 밸런서 사이에서는 HTTPS로 통신함으로써 높은 보안성을 확보하고, 
    서버에게는 HTTP 트래픽을 넘겨줌으로써 복호화에 드는 CPU 부하를 줄일 수 있다.

## 로드밸런서의 기본 동작 방식

1. 클라이언트의 브라우저에서 naver.com이라고 입력
2. 클라이언트에 설정된 **메인 DNS Server로 naver.com의 IP 주소를 문의**
3. 메인 DNS Server는 naver.com 주소를 관리하는 별도의 DNS Server에 IP 주소 문의
4. 별도 관리 DNS Server는 **로드밸런서의 IP (Virtual IP) 주소를 메인 DNS Server에게 알려줌**
5. 메인 DNS Server는 **획득한 VIP 주소를 클라이언트에 전송**
6. 클라이언트에서 **로드밸런서의 VIP 주소로 http 요청**
7. 로드밸런서는 별도 **로드밸런싱 방법 (ex. 라운드 로빈 등) 을 통하여 서버에게 요청을 전송**
8. 서버의 작업 결과를 받은 **로드밸런서는 전달받은 http 결과를 클라이언트에게 전송**

## 로드밸런서의 기본 기능

* **Health Check**

  * 기본적으로 보통의 로드밸런서는 서버들 (또는 다음의 노드)에 대한 주기적인 Health Check를 통해 **서버들의 장애 여부를 판단**할 수 있다.
  * 이로 인해 로드밸런서가 있을 때 **서버 몇 대에 이상이 생기더라도 다른 정상 동작중인 서버로 트래픽을 보내주는 Fail-over가 가능**하며, 또한
  TCP/UDP 분석이 가능하기 때문에 Firewall의 역할도 수행할 수 있다.

> L3 체크 : ICMP (TCP/IP에서 IP 패킷을 처리할 때 발생되는 문제를 알려주는 프로토콜) 를 이용하여 서버의 IP 주소가 통신 가능한 상태인지를 확인   

> L4 체크 : TCP는 3 Way-Handshaking(전송->확인/전송->확인)를 기반으로 통신한다. 이러한 **TCP의 특성을 바탕으로 각 포트 상태를 체크하는 방식**이다.
예를 들어, HTTP 웹 서버의 경우 80 port를 사용하므로 **TCP 80 port에 대한 체크를 통해 서버가 살아 있는 상태인지 확인**한다.    

> L7 체크 : **어플리케이션 계층에서 체크**를 한다. 즉, **실제 웹 페이지(ex. .../index.html)에 통신을 시도하여 이상 유무를 파악**한다.

* **Tunneling**
  
  * 눈에 보이지 않는 통로를 만들어 통신할 수 있게 하는 개념으로, **로드밸런서는 클라이언트와 서버 간 중간에서 터널링을 제공**해준다.
  즉, **연결된 상호 간에만 캡슐화된 패킷을 구별해 캡슐화를 해제**하게 한다.
  
* **NAT (Network Address Translation)**

  * **IP 주소를 변환해주는 기능** (목적지와 수신지의 IP 주소와 TCP/UDP 포트를 재기록하여 변환하며 네트워크 트래픽을 주고 받을 수 있다.)
  * 내부 네트워크에서 사용하던 사설 IP 주소를 로드밸런서 외부의 공인 IP 주소로 변경해준다. 
  * 부족한 공인 IP 주소를 효율적으로 사용할 수 있지만, 로드밸런싱 관점에서는 여러개의 호스트가 하나의 공인 IP 주소 (VIP) 를 통해 접속하는 것이 주 목적이다.
  
  > SNAT (Source Network Address Translation)
  : **내부에서 외부로 트래픽이 나가는 경우**, 내부 사설 IP 주소를 외부의 공인 IP 주소로 변환하는 방식이다. 집에서 사용하는 공유기가 대표적

  > DNAT (Destination Network Address Translation)
  : **외부에서 내부로 트래픽이 들어오는 경우**, 외부 공인 IP 주소를 내부의 사설 IP 주소로 변환하는 방식이다. 로드밸런서가 대표적인 예
  
  <p align="center"><img src="https://user-images.githubusercontent.com/50662573/107877951-d515c400-6f12-11eb-879c-df236ea8a84d.png" width="70%" height="70%"></img></p>


* **DSR (Direct Server Routing)**

  * 서버에서 클라이언트로 되돌아가는 경우, 목적지를 클라이언트로 설정한 다음 네트워크 장비나 로드밸런서를 거치지 않고 바로 클라이언트를 찾아가는 방식이다.
  이 경우, 로드밸런서의 부하를 줄여줄 수 있는 장점이 있다.
   
   
   

[정리 잘 되어있는 블로그 - https://post.naver.com/viewer/postView.nhn?volumeNo=27046347&memberNo=2521903]
